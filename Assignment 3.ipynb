{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. 1. Build a ANN model from scratch for predicting best housing selling prices in Boston using three features (i.e. “RM: average number of rooms per dwelling; LSTAT: percentage of population considered lower status: PTRATIO: pupil-teacher ratio by town”) of Boston dataset (Use Sklearn Dataset) by using Stochastic Gradient Descent algorithm for the loss functions: \n",
    "- (a) Mean Square Error \n",
    "- (b) Huber Loss \n",
    "- (c) Squared Epsilon Hinge Loss \n",
    "- (i) Plot comparative loss curve for at least 500 epochs.\n",
    "- (ii) Print comparison of Boston housing selling prices among above mentioned loss functions using bar chart plot and which loss function is providing better housing selling prices among others.\n",
    "- (iii) Implement above ANN model with Keras Library and verify the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. 2. Build a ANN model from to recognize breast cancer from Breast Dataset (Use Sklearn Dataset). Use Stochastic gradient descent algorithm to learn model with parameters for α = 0.01 and random parameters of the parameters of the ANN model for loss functions \n",
    "- (a) Binary cross entropy \n",
    "- (b) Dice Loss \n",
    "- (i) Plot comparative loss curve for at least 200 epochs.\n",
    "- (ii) Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy and ROUC curve for each loss function.\n",
    "- (iii) Repeat part (ii) to (iii) using Adam gradient descent algorithm\n",
    "- (iv) Implement above ANN model with Keras Library and verify the above results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q.3. Build a ANN model from scratch to recognize diabetes-from pima-indians-diabetes-database (i.e. https://github.com/duonghuuphuc/keras/tree/master/dataset ). Use Stochastic gradient descent algorithm to learn model with parameters for α = 0.01 and random parameters of the ANN model for loss functions \n",
    "- (a) Binary cross entropy \n",
    "- (b) Dice Loss \n",
    "- (i) Visualize input dataset and Plot comparative loss curve for at least 200 epochs.\n",
    "- (ii) Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy and ROUC curve for each loss function.\n",
    "- (iii) Repeat part (i) to (ii) using Adam gradient descent algorithm\n",
    "- (iv) Implement above ANN model with Keras Library and verify the above results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. 4. Build a ANN model from scratch to recognize Iris-setosa, Iris -virginica and Iris-versicolor from the Iris Dataset ((Use Sklearn Dataset) which contains four features (length and width of sepals and petals) of 50 samples of three species of Iris (Iris setosa, Iris virginica and Iris versicolor. For implementation, use Stochastic gradient descent algorithm to learn model with parameters for α = 0.01and random parameters of the ANN model for the Softmax loss function \n",
    "- (i)Visualize data by boxplot of Sepal Length & Sepal width and Petal Length and width for three IRIS\n",
    "species. \n",
    "- (ii) Plot comparative loss curve for at least 200 epochs.\n",
    "- (iii) Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy and ROUC curve\n",
    "- (iv) Visualize classified data by Scatter plot\n",
    "- (v) Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy and ROUC curve for each loss function.\n",
    "- (vi) Repeat part (ii) to (v) using Adam gradient descent algorithm\n",
    "- (vii) Implement above ANN model with Keras Library and verify the above results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. 5. Build a ANN model from scratch to recognize human emotion using Facial emotion recognition dataset (FER2013) (https://github.com/gitshanks/fer2013). For implementation, use Stochastic gradient descent algorithm to learn model with parameters for α = 0.01 and random parameters of the ANN model for the Softmax loss function \n",
    "- (i)Visualize Facial emotion recognition dataset (FER2013. \n",
    "- (ii) Plot comparative loss curve for at least 200 epochs.\n",
    "- (iii)Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy and ROUC curve\n",
    "- (iv) Repeat part (ii) to (iii) using Adam gradient descent algorithm\n",
    "- (v) Implement above ANN model with Keras Library and verify the above result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook as tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Input, Derivative = False , dE = None):\n",
    "    \n",
    "    if(Derivative):\n",
    "        Soft = np.array([softmax(Input)])\n",
    "        der = Soft*(np.identity(len(Input)) - np.transpose(Soft))\n",
    "        output = np.matmul(np.array([dE]),der)[0]\n",
    "        return output\n",
    "    else:\n",
    "        Input = np.array(Input)\n",
    "        Numerator = np.exp(Input)\n",
    "        output = Numerator/sum(Numerator)\n",
    "        return (output)\n",
    "\n",
    "def sigmoid_activation(Input, Derivative = False , dE = None):\n",
    "    if(Derivative):\n",
    "        S = sigmoid_activation(Input)\n",
    "        out = S*(1-S) * dE\n",
    "        return(out)\n",
    "    else:\n",
    "        \n",
    "        output = np.exp(Input)/(np.exp(Input)+1)\n",
    "        return(output)\n",
    "\n",
    "def neuron_forward(X,Params):\n",
    "    W,B = Params\n",
    "    out = np.dot(X,W) + B\n",
    "    activated = sigmoid_activation(out)\n",
    "    \n",
    "    if(np.isnan(activated).any()):\n",
    "        print(\"Debug logs:\")\n",
    "        print(\"X:\",X)\n",
    "        print(\"W:\",W)\n",
    "        print(\"B:\",B)\n",
    "        print(\"Out:\",out)\n",
    "        print(\"Activated:\",activated)\n",
    "        raise Exception(\"Nan detected!\")\n",
    "        \n",
    "    return activated\n",
    "\n",
    "def neuron_backward(dE,X,Params):\n",
    "    W,B = Params\n",
    "    dE = sigmoid_activation(np.dot(X,W) + B,Derivative = True,dE = dE)\n",
    "    dW = np.array(dE)*X\n",
    "    dB = dE\n",
    "    W = W - dW\n",
    "    B = B - dB\n",
    "    dX = np.array(dE)*W\n",
    "    return (W,B),(dX)\n",
    "\n",
    "def add_dense_layer(N_Neurons, Model = [], input_size = None ):\n",
    "    \n",
    "    if(input_size==None):\n",
    "        input_size = len(Model[-1])\n",
    "        \n",
    "    new_layer = []\n",
    "    for i in range(N_Neurons):\n",
    "        new_layer = new_layer + [(np.random.rand(input_size),np.random.rand())]\n",
    "    Model = Model + [new_layer]\n",
    "    \n",
    "    return Model\n",
    "\n",
    "def Forward_propogation(Model , X ,Activation = None):\n",
    "    All_outputs = [X]\n",
    "    for layer in Model:\n",
    "        Layer_output = []\n",
    "        for neuron in layer:\n",
    "            Layer_output = Layer_output + [neuron_forward(All_outputs[-1],neuron)]\n",
    "        All_outputs = All_outputs + [Layer_output]\n",
    "        \n",
    "    if(Activation != None):\n",
    "        All_outputs = All_outputs + [Activation(All_outputs[-1])]\n",
    "    else:\n",
    "        All_outputs = All_outputs + [All_outputs[-1]]\n",
    "        \n",
    "    return All_outputs\n",
    "        \n",
    "def Back_propogation(Model,Outputs,Error,Activation = None):\n",
    "    if(Activation != None):\n",
    "        Error = Activation(Outputs[-1], Derivative = True , dE = Error)\n",
    "        \n",
    "    n_layers = len(Model)\n",
    "    Input_errors = np.array(Error)\n",
    "    \n",
    "    for i in range(n_layers):\n",
    "        Out_Error = 0\n",
    "\n",
    "        for j in range(len(Model[n_layers - i -1])):\n",
    "            Model[n_layers - i -1][j] , dX = neuron_backward(Input_errors[j],Outputs[n_layers - i -1],Model[n_layers - i -1][j])\n",
    "            Out_Error = Out_Error + dX\n",
    "        Input_errors = Out_Error.copy()\n",
    "        \n",
    "    return Model\n",
    "\n",
    "def display_weights(Model):\n",
    "    print(\"\\n*********************************************\")\n",
    "    for i,layer in enumerate(Model):\n",
    "        print(\"\\n--------Layer {}---------\".format(i+1))\n",
    "        for node in layer:\n",
    "            print(node)\n",
    "    print(\"*********************************************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emotions:  [0 2 4 6 3 5 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>Usage</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Training</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Training</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Training</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion     Usage                                             pixels\n",
       "0        0  Training  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...\n",
       "1        0  Training  151 150 147 155 148 133 111 140 170 174 182 15...\n",
       "2        2  Training  231 212 156 164 174 138 161 173 182 200 106 38...\n",
       "3        4  Training  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...\n",
       "4        6  Training  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84..."
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"challenges-in-representation-learning-facial-expression-recognition-challenge/\"\n",
    "data = pd.read_csv(path+'icml_face_data.csv')\n",
    "\n",
    "print(\"Number of emotions: \",data['emotion'].unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,Y_train = prepare_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35887, 48, 48) (35887,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_train),np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = add_dense_layer(7,input_size =48*48)\n",
    "Model = add_dense_layer(7,Model)\n",
    "Model = add_dense_layer(7,Model)\n",
    "# display_weights(Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac7cced00d14b62baa75943b40a7474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*********************************************\n",
      "\n",
      "--------Layer 1---------\n",
      "(array([0.21124665, 0.01505739, 0.27947815, ..., 0.36104707, 0.61640066,\n",
      "       0.5311541 ]), 0.8630128316114897)\n",
      "(array([0.12827231, 0.53057393, 0.58784118, ..., 0.09918642, 0.02227738,\n",
      "       0.08405145]), 0.04684262208899892)\n",
      "(array([0.50271253, 0.09928989, 0.32871982, ..., 0.34523604, 0.81057335,\n",
      "       0.43090422]), 0.22982960384409268)\n",
      "(array([0.51622197, 0.11401057, 0.21770291, ..., 0.55152366, 0.27833287,\n",
      "       0.0313195 ]), 0.9391868677588338)\n",
      "(array([0.56462098, 0.4353721 , 0.80137654, ..., 0.35891892, 0.52081978,\n",
      "       0.66782292]), 0.7533723850119036)\n",
      "(array([0.85836477, 0.71659625, 0.09267893, ..., 0.3792522 , 0.01689892,\n",
      "       0.68985289]), 0.12202942442940046)\n",
      "(array([0.44059837, 0.37151685, 0.14367438, ..., 0.34135419, 0.91844012,\n",
      "       0.93452209]), 0.4326695996489279)\n",
      "\n",
      "--------Layer 2---------\n",
      "(array([0.49157251, 0.8627586 , 0.71280596, 0.43102267, 0.02707028,\n",
      "       0.99200285, 0.4268604 ]), 0.7163387302639733)\n",
      "(array([0.36437871, 0.52510837, 0.74582776, 0.43447024, 0.98711396,\n",
      "       0.30939306, 0.37312904]), 0.34718390224743245)\n",
      "(array([0.07785959, 0.07111592, 0.69849527, 0.18218521, 0.50004087,\n",
      "       0.29582608, 0.19236629]), 0.1302365133186366)\n",
      "(array([0.97330184, 0.40103992, 0.71909224, 0.9529716 , 0.74923306,\n",
      "       0.5533516 , 0.35991585]), 0.9397795738952173)\n",
      "(array([0.50030838, 0.58748338, 0.01026892, 0.93232354, 0.24277735,\n",
      "       0.44970513, 0.02789423]), 0.7707002422153735)\n",
      "(array([0.4341935 , 0.12175862, 0.62549888, 0.37788023, 0.23178981,\n",
      "       0.30349601, 0.03966301]), 0.6847776532908832)\n",
      "(array([0.04253827, 0.11681592, 0.93122838, 0.88426847, 0.60560276,\n",
      "       0.03357359, 0.91261937]), 0.8195328677716773)\n",
      "\n",
      "--------Layer 3---------\n",
      "(array([0.12746708, 0.29251157, 0.70861233, 0.60188246, 0.1795252 ,\n",
      "       0.41406783, 0.46917498]), 0.6124431520206951)\n",
      "(array([0.21541802, 0.01661355, 0.71580775, 0.97956982, 0.99400642,\n",
      "       0.44064897, 0.23776121]), 0.43038622374220614)\n",
      "(array([0.26064914, 0.7590146 , 0.95083817, 0.63598639, 0.29936068,\n",
      "       0.45060057, 0.6738254 ]), 0.5457845945078678)\n",
      "(array([0.43876814, 0.4447937 , 0.01976748, 0.95219501, 0.33264775,\n",
      "       0.63364703, 0.48735877]), 0.28238777712003144)\n",
      "(array([0.67961146, 0.4277236 , 0.04162607, 0.6373046 , 0.02000783,\n",
      "       0.99723693, 0.77172824]), 0.12212322780364712)\n",
      "(array([0.28052194, 0.40731721, 0.28213845, 0.6216381 , 0.71343828,\n",
      "       0.77008061, 0.93053115]), 0.8967869035101044)\n",
      "(array([0.54291742, 0.78046381, 0.91099526, 0.22704459, 0.07030127,\n",
      "       0.09320134, 0.46204945]), 0.2786060648420119)\n",
      "*********************************************\n",
      "\n",
      "[array([0.2745098 , 0.31372549, 0.32156863, ..., 0.41568627, 0.42745098,\n",
      "       0.32156863]), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.9906263233445217, 0.9834812918814939, 0.8954935041629122, 0.996490218997787, 0.9712922746724275, 0.9436970215519936, 0.9872095009773395], [0.9640503020097563, 0.980028727900609, 0.9880723271916184, 0.971341783438684, 0.9736798174551715, 0.9917207294273304, 0.9622547823276055], array([0.14116963, 0.14344341, 0.14460187, 0.14220272, 0.14253559,\n",
      "       0.1451304 , 0.14091638])]\n",
      "\n",
      "*********************************************\n",
      "\n",
      "--------Layer 1---------\n",
      "(array([0.21124665, 0.01505739, 0.27947815, ..., 0.36104707, 0.61640066,\n",
      "       0.5311541 ]), 0.8630128316114897)\n",
      "(array([0.12827231, 0.53057393, 0.58784118, ..., 0.09918642, 0.02227738,\n",
      "       0.08405145]), 0.04684262208899892)\n",
      "(array([0.50271253, 0.09928989, 0.32871982, ..., 0.34523604, 0.81057335,\n",
      "       0.43090422]), 0.22982960384409268)\n",
      "(array([0.51622197, 0.11401057, 0.21770291, ..., 0.55152366, 0.27833287,\n",
      "       0.0313195 ]), 0.9391868677588338)\n",
      "(array([0.56462098, 0.4353721 , 0.80137654, ..., 0.35891892, 0.52081978,\n",
      "       0.66782292]), 0.7533723850119036)\n",
      "(array([0.85836477, 0.71659625, 0.09267893, ..., 0.3792522 , 0.01689892,\n",
      "       0.68985289]), 0.12202942442940046)\n",
      "(array([0.44059837, 0.37151685, 0.14367438, ..., 0.34135419, 0.91844012,\n",
      "       0.93452209]), 0.4326695996489279)\n",
      "\n",
      "--------Layer 2---------\n",
      "(array([0.4915719 , 0.862758  , 0.71280535, 0.43102206, 0.02706967,\n",
      "       0.99200224, 0.4268598 ]), 0.7163381254340452)\n",
      "(array([0.36437862, 0.52510828, 0.74582766, 0.43447015, 0.98711386,\n",
      "       0.30939297, 0.37312894]), 0.347183806200359)\n",
      "(array([0.07787595, 0.07113228, 0.69851163, 0.18220157, 0.50005722,\n",
      "       0.29584243, 0.19238264]), 0.13025286999900781)\n",
      "(array([0.97330214, 0.40104022, 0.71909254, 0.95297191, 0.74923337,\n",
      "       0.5533519 , 0.35991615]), 0.9397798781576093)\n",
      "(array([0.50030816, 0.58748316, 0.0102687 , 0.93232333, 0.24277713,\n",
      "       0.44970491, 0.02789401]), 0.7707000253801503)\n",
      "(array([0.43419562, 0.12176074, 0.62550099, 0.37788234, 0.23179192,\n",
      "       0.30349813, 0.03966513]), 0.6847797674224105)\n",
      "(array([0.04253898, 0.11681663, 0.93122909, 0.88426919, 0.60560348,\n",
      "       0.03357431, 0.91262008]), 0.8195335784689077)\n",
      "\n",
      "--------Layer 3---------\n",
      "(array([0.12788771, 0.29292917, 0.70899257, 0.60230558, 0.17993763,\n",
      "       0.41446853, 0.46959417]), 0.6128677656518129)\n",
      "(array([0.21537833, 0.01657415, 0.71577188, 0.97952989, 0.99396751,\n",
      "       0.44061116, 0.23772166]), 0.43034616068723125)\n",
      "(array([0.26062502, 0.75899066, 0.95081637, 0.63596213, 0.29933703,\n",
      "       0.45057759, 0.67380137]), 0.5457602474609292)\n",
      "(array([0.43871225, 0.44473822, 0.01971696, 0.95213879, 0.33259295,\n",
      "       0.63359379, 0.48730307]), 0.282331361053151)\n",
      "(array([0.67955987, 0.42767239, 0.04157944, 0.6372527 , 0.01995725,\n",
      "       0.99718778, 0.77167682]), 0.12207115051876084)\n",
      "(array([0.28050507, 0.40730045, 0.2821232 , 0.62162113, 0.71342174,\n",
      "       0.77006454, 0.93051433]), 0.8967698701632513)\n",
      "(array([0.54284525, 0.78039217, 0.91093002, 0.226972  , 0.07023052,\n",
      "       0.09313259, 0.46197753]), 0.27853321615864185)\n",
      "*********************************************\n",
      "\n",
      "[array([0.59215686, 0.58823529, 0.57647059, ..., 0.75686275, 0.71764706,\n",
      "       0.72156863]), [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], [0.9906262784137246, 0.9834812793985658, 0.8955057494340076, 0.996490227510947, 0.9712922263032291, 0.9436979201856597, 0.9872095727683758], [0.9641615858434645, 0.9800229839702074, 0.9880703022463565, 0.9713299435969426, 0.9736697732231206, 0.9917197073774741, 0.9622352036056261], array([0.14118413, 0.14344136, 0.14460034, 0.14219982, 0.14253294,\n",
      "       0.145129  , 0.14091242])]\n",
      "Debug logs:\n",
      "X: [0.90588235 0.83137255 0.61176471 ... 0.34509804 0.43137255 0.59607843]\n",
      "W: [0.21124665 0.01505739 0.27947815 ... 0.36104707 0.61640066 0.5311541 ]\n",
      "B: 0.8630128316114897\n",
      "Out: 710.2623691941881\n",
      "Activated: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-202-7c1ffb2eb336>:20: RuntimeWarning: overflow encountered in exp\n",
      "  output = np.exp(Input)/(np.exp(Input)+1)\n",
      "<ipython-input-202-7c1ffb2eb336>:20: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  output = np.exp(Input)/(np.exp(Input)+1)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Nan detected!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-203-9bb06dc2a198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#Obtain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mOutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mForward_propogation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;31m#Save prediction for plotting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-7c1ffb2eb336>\u001b[0m in \u001b[0;36mForward_propogation\u001b[1;34m(Model, X, Activation)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mLayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0mLayer_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLayer_output\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mneuron_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAll_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m         \u001b[0mAll_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAll_outputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mLayer_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-202-7c1ffb2eb336>\u001b[0m in \u001b[0;36mneuron_forward\u001b[1;34m(X, Params)\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Out:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Activated:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Nan detected!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mactivated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Nan detected!"
     ]
    }
   ],
   "source": [
    "# Outputs = Forward_propogation(Model,[0.1,0.1])\n",
    "# print(Outputs)\n",
    "# display_weights(Model)\n",
    "# Model = Back_propogation(Model,Outputs,[2,1])\n",
    "# display_weights(Model)\n",
    "n_classes = 7\n",
    "learning_rate = 0.1\n",
    "Epochs = 10\n",
    "Loss = []\n",
    "\n",
    "for i in tqdm.tqdm(range(Epochs)):\n",
    "    for X,Truth in zip(X_train,Y_train):\n",
    "        X = X.flatten()/255\n",
    "        record = []\n",
    "        #Obtain \n",
    "        Outputs = Forward_propogation(Model,X,softmax)\n",
    "\n",
    "        #Save prediction for plotting\n",
    "        record = record + [np.argmax(Outputs[-1]) == Truth]\n",
    "        \n",
    "        #Calculate error\n",
    "        temp = [0]*n_classes\n",
    "        temp[Truth] = 1\n",
    "        Error = (Outputs[-1] - temp)* learning_rate\n",
    "        \n",
    "        display_weights(Model)\n",
    "        print(Outputs)\n",
    "        \n",
    "        #Backpropogate using error\n",
    "        Model = Back_propogation(Model,Outputs,Error,softmax)\n",
    "    Loss = Loss + [np.mean(record)]\n",
    "    \n",
    "plt.plot(Loss)\n",
    "plt.show\n",
    "print(Outputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
