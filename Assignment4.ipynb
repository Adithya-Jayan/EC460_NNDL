{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4:CNN with Applications\n",
    "### Adithya Jayan - 181EC102 | Anvith M - 181EC105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tqdm.notebook as tqdm\n",
    "import pandas as pd\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten, AvgPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.keras import TqdmCallback\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q.1.\n",
    "- (i) Write python code for plotting the following activation functions and their derivative for the input x in the range of -20 to 20. \n",
    "    - (a) ReLU \n",
    "    - (b) LekayReLU \n",
    "    - (c) Parametric ReLU \n",
    "    - (d) Exponential ReLU(ELU) \n",
    "    - (e) Scaled Exponential Linear Units (SELU) \n",
    "    - (f) SoftPlus (Smooth ReLU) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Defining required functions for part 1.(i)\n",
    "\n",
    "def plot_relu(Input,plot=1):\n",
    "    output = Input.copy()\n",
    "    output[output<0] = 0\n",
    "    \n",
    "    derivative = np.ones_like(Input)\n",
    "    derivative[Input<0] = 0\n",
    "        \n",
    "    if(plot):\n",
    "        plt.figure()\n",
    "        plt.title(\"ReLU plot\")\n",
    "        plt.plot(Input,output)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(\"ReLU derivative plot\")\n",
    "        plt.plot(Input,derivative)\n",
    "    return(output)\n",
    "\n",
    "def plot_leaky_relu(Input,plot=1):\n",
    "    output = Input.copy()\n",
    "    derivative = np.ones_like(Input)\n",
    "    for i in range(len(Input)):\n",
    "        if(Input[i]<0): \n",
    "            output[i]=Input[i]*0.01\n",
    "            derivative[i] = 0.01\n",
    "    if(plot):\n",
    "        plt.figure()\n",
    "        plt.title(\"Leaky ReLU plot\")\n",
    "        plt.plot(Input,output)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(\"Leaky ReLU derivative plot\")\n",
    "        plt.plot(Input,derivative)\n",
    "    return(output)\n",
    "\n",
    "def plot_Parametric_relu(Input,alpha,plot=1):\n",
    "    output = Input.copy()\n",
    "    derivative = np.ones_like(Input)\n",
    "    for i in range(len(Input)):\n",
    "        if(Input[i]<0): \n",
    "            output[i]=Input[i]*alpha\n",
    "            derivative[i] = alpha\n",
    "    if(plot):\n",
    "        plt.figure()\n",
    "        plt.title(\"Parametric ReLU plot\")\n",
    "        plt.plot(Input,output)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(\"Parametric ReLU derivative plot\")\n",
    "        plt.plot(Input,derivative)\n",
    "    return(output)\n",
    "\n",
    "def plot_Exponential_relu(Input,alpha,plot=1):\n",
    "    output = Input.copy()\n",
    "    derivative = np.ones_like(Input)\n",
    "    for i in range(len(Input)):\n",
    "        if(Input[i]<0): \n",
    "            output[i]=(np.exp(Input[i])-1)*alpha\n",
    "            derivative[i] = output[i] + alpha\n",
    "    if(plot):\n",
    "        plt.figure()\n",
    "        plt.title(\"ELU plot\")\n",
    "        plt.plot(Input,output)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(\"ELU derivative plot\")\n",
    "        plt.plot(Input,derivative)\n",
    "    return(output)\n",
    "\n",
    "def plot_Scaled_Exponential_relu(Input,alpha,lamda,plot=1):\n",
    "    output = Input.copy()\n",
    "    derivative = np.ones_like(Input)\n",
    "    for i in range(len(Input)):\n",
    "        if(Input[i]<0): \n",
    "            output[i]=(np.exp(Input[i])-1)*alpha\n",
    "            derivative[i] = (np.exp(Input[i]))*alpha\n",
    "    output = output*lamda\n",
    "    if(plot):\n",
    "        plt.figure()\n",
    "        plt.title(\"Scaled ELU plot\")\n",
    "        plt.plot(Input,output)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(\"Scaled ELU derivative plot\")\n",
    "        plt.plot(Input,derivative)\n",
    "    return(output)\n",
    "\n",
    "def plot_Smooth_relu(Input,plot=1):\n",
    "    output = np.log(1+np.exp(Input))\n",
    "    derivative = 1/(1+np.exp(-1*Input))\n",
    "    if(plot):\n",
    "        plt.figure()\n",
    "        plt.title(\"SoftPlus plot\")\n",
    "        plt.plot(Input,output)\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.title(\"SoftPlus derivative plot\")\n",
    "        plt.plot(Input,derivative)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Solution for 1.(i)\n",
    "\n",
    "#Defining Input range\n",
    "Input = np.linspace(-20,20,100)\n",
    "\n",
    "#Defining required parameters\n",
    "alpha = 0.1\n",
    "lamda = 0.5\n",
    "\n",
    "#Calculation and plotting via function call\n",
    "plot_relu(Input,plot=1);\n",
    "plot_leaky_relu(Input,plot=1);\n",
    "plot_Parametric_relu(Input,alpha,plot=1);\n",
    "plot_Exponential_relu(Input,alpha,plot=1);\n",
    "plot_Scaled_Exponential_relu(Input,alpha,lamda,plot=1);\n",
    "plot_Smooth_relu(Input,plot=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1.\n",
    "- (ii)\n",
    "    - (a).Write python from scratch for 2D Linear convolution between input=np.array([[1,2,3],[4,5,6],[7,8,9]])and filter=np.array([[1,2,1],[0,0,0],[-1,-2,-1]]) \n",
    "    - (b).Write python from scratch for 2D Linear convolution by Toeplitz matrix method between input image(lena.jpg) and kernel = np.array([[1, 2, 1],[2, 4, 2],[1, 2, 1]]))/16 \n",
    "    - (c) Compute number of multiplications and parameters required for 2D Linear Convolution in part (a) and part(b) \n",
    "    - (d) Apply Max pooling and Average pooling on convoled image in part (b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for part 1.(ii).(a)\n",
    "\n",
    "def convolve(Image,kernel,padding = (0,0),s = 1):\n",
    "    \n",
    "    kernel = np.flipud(np.fliplr(kernel))\n",
    "    p1,p2 = padding\n",
    "    \n",
    "    x,y = Image.shape\n",
    "\n",
    "    x_k,y_k = kernel.shape\n",
    "\n",
    "    out_x = (x-x_k+2*p1)//s+1\n",
    "    out_y = (y-y_k+2*p2)//s+1\n",
    "    \n",
    "    out = np.zeros((out_x,out_y))\n",
    "    \n",
    "    Img_padded = np.zeros((x+2*p1,y+2*p2))\n",
    "    Img_padded[p1:p1+x,p2:p2+y] = Image\n",
    "    Image = Img_padded\n",
    "    \n",
    "    for i in range(out_x):\n",
    "        i_img = i*s\n",
    "        for j in range(out_y):\n",
    "            j_img = j*s\n",
    "            out[i,j] = np.sum(Image[i_img:i_img+x_k,j_img:j_img+y_k]*kernel)\n",
    "            \n",
    "    print(\"Convolution:\\n\",out)\n",
    "    print(\"\\nTotal number of multiplications is: \",(out_x*out_y*x_k*y_k))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution for part 1.(ii).(a)\n",
    "\n",
    "Image = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(\"Image:\\n\",Image)\n",
    "\n",
    "kernel = np.array([[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    "print(\"Kernel:\\n\",kernel)\n",
    "\n",
    "convolved = convolve(Image,kernel,(1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for part 1.(ii).(b) and 1.(ii).(c)\n",
    "def rightrotate(arr):\n",
    "    l = len(arr)\n",
    "    y = arr[l-1]\n",
    "    for n in range(l-1,-1,-1):\n",
    "        arr[n] = arr[n-1]\n",
    "    arr[n] = y\n",
    "    return arr\n",
    "\n",
    "def convolve2dmatrix(input,kernel):\n",
    "    r1 = np.shape(input)[0]\n",
    "    c1 = np.shape(input)[1]\n",
    "    r2 = np.shape(kernel)[0]\n",
    "    c2 = np.shape(kernel)[1]\n",
    "\n",
    "    #dimensions of output\n",
    "    r3 = r1+r2-1\n",
    "    c3 = c1+c1-1\n",
    "\n",
    "    #zero padding kernel\n",
    "    kernel = np.pad(kernel,((0,r3-r2),(0,c3-c2)), 'constant')\n",
    "\n",
    "    #Creating toeplitz submatrices\n",
    "    mylist = []\n",
    "    for i in range(r3):\n",
    "        x = kernel[i]\n",
    "        for j in range(c1):\n",
    "            if (j==0):\n",
    "                temp = np.array([x])\n",
    "            else:\n",
    "                x = rightrotate(x)\n",
    "                temp = np.vstack((temp,x))\n",
    "        mylist.append(temp)\n",
    "  \n",
    "    #Creating the Blocked Toeplitz matrix\n",
    "    #soft coded for general case\n",
    "    templist = mylist\n",
    "    length = len(templist)\n",
    "    for j in tqdm.tqdm(range(c1),leave=False,desc = \"Convolution progress\"):\n",
    "        if (j==0):\n",
    "            for k in range(length):\n",
    "                if (k==0):\n",
    "                    H = np.block([templist[0]])\n",
    "                else:\n",
    "                    H = np.block([H,templist[k]])\n",
    "            Hfinal = np.block(H)\n",
    "        else:\n",
    "            templist = rightrotate(templist)\n",
    "            for k in range(length):\n",
    "                if (k==0):\n",
    "                    H = np.block([templist[0]])\n",
    "                else:\n",
    "                    H = np.block([H,templist[k]])\n",
    "            Hfinal = np.block([[Hfinal],[H]])\n",
    "    Hfinal = np.transpose(Hfinal)\n",
    "\n",
    "    #reshape input matrix\n",
    "    input = np.reshape(input,r1*c1)\n",
    "\n",
    "    #multiply both\n",
    "    result_vector = np.matmul(Hfinal, input)\n",
    "\n",
    "    #reshape output vector\n",
    "    result_vector = np.reshape(result_vector,(r3,c3))\n",
    "    \n",
    "    crop = result_vector[0:102, 0:102]\n",
    "    plt.imshow(crop,cmap='gray')\n",
    "    plt.title(\"Convolved Image:\")\n",
    "    plt.show()\n",
    "    print(\"\")\n",
    "    \n",
    "    return crop\n",
    "    \n",
    "def computemultiplications(img,kernel):\n",
    "    Dfr = np.shape(img)[0]\n",
    "    Dfc = np.shape(img)[1]\n",
    "    Dkr = np.shape(kernel)[0]\n",
    "    Dkc = np.shape(kernel)[1]\n",
    "\n",
    "    #dimensions of output\n",
    "    Dpr = Dfr+Dkr-1\n",
    "    Dpc = Dfc+Dkc-1\n",
    "\n",
    "    total = (Dkr**2)*(Dpr**2)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution for part 1.(ii).(b) and 1.(ii).(c)\n",
    "\n",
    "input2 = cv2.imread('lena.tif',0)\n",
    "input2 = cv2.resize(input2,(100,100))\n",
    "kernel2 = np.array([[1,2,1],[2,4,2],[1,2,1]])\n",
    "kernel2 = kernel2/16\n",
    "\n",
    "plt.imshow(input2,cmap='gray')\n",
    "plt.title(\"Image:\")\n",
    "plt.show()\n",
    "print(\"Kernel:\\n\",kernel2)\n",
    "print(\"\")\n",
    "\n",
    "#Converting image to numpy array\n",
    "input2 = np.array(input2)\n",
    "\n",
    "#Calling Convolve2dmatrix\n",
    "convolved = convolve2dmatrix(input2,kernel2)\n",
    "\n",
    "#Compute Multiplications\n",
    "print(\"The total number of multiplications are:\",computemultiplications(input2,kernel2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for part 1.(ii).(d)\n",
    "\n",
    "def Max_pooling(Image,kernel_size):\n",
    "    \n",
    "    x,y = Image.shape\n",
    "\n",
    "    x_k,y_k = kernel_size\n",
    "\n",
    "    out_x = (x-x_k)+1\n",
    "    out_y = (y-y_k)+1\n",
    "    \n",
    "    out = np.zeros((out_x,out_y))\n",
    "        \n",
    "    for i in range(out_x):\n",
    "        for j in range(out_y):\n",
    "            out[i,j] = np.max(Image[i:i+x_k,j:j+y_k])\n",
    "            \n",
    "    plt.imshow(out,cmap='gray')\n",
    "    plt.title(\"Max_pooled Image:\")\n",
    "    plt.show()        \n",
    "    \n",
    "#Functions for part (d)\n",
    "\n",
    "def Average_pooling(Image,kernel_size):\n",
    "    \n",
    "    x,y = Image.shape\n",
    "\n",
    "    x_k,y_k = kernel_size\n",
    "\n",
    "    out_x = (x-x_k)+1\n",
    "    out_y = (y-y_k)+1\n",
    "    \n",
    "    out = np.zeros((out_x,out_y))\n",
    "        \n",
    "    for i in range(out_x):\n",
    "        for j in range(out_y):\n",
    "            out[i,j] = np.mean(Image[i:i+x_k,j:j+y_k])\n",
    "            \n",
    "    plt.imshow(out,cmap='gray')\n",
    "    plt.title(\"Average_pooled Image:\")\n",
    "    plt.show()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solution for part 1.(ii).(d)\n",
    "\n",
    "Max_pooling(convolved,(3,3))\n",
    "Average_pooling(convolved,(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q1.\n",
    "- (iii) \n",
    "    - (a)Write python from scratch for 2D Spatial Separbale convolution between input image(lena.jpg) and Gausian filter = np.array([1,4,6,4,1],[4,16,24,16,4],[6,24,36,24,6],[4,16,24,16,4],[1,4,6,4,1])/256 \n",
    "    - (b) Compute number of multiplications and parameters required for2D Spatial Separbale convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Inputs\n",
    "Image = cv2.imread('lena.tif',0) #Image\n",
    "Image = cv2.resize(Image,(100,100)) \n",
    "Image = np.array(Image)\n",
    "\n",
    "plt.imshow(Image,cmap='gray')\n",
    "plt.title(\"Input Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter1 = np.array([[1,4,6,4,1]])\n",
    "filter2 = np.reshape(filter1,(5,1)) #Column filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_image = convolve(Image,filter2) #Intermediate Image\n",
    "plt.imshow(inter_image,cmap='gray')\n",
    "plt.title(\"Intermediate Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image = convolve(inter_image,filter1) #final Output\n",
    "\n",
    "plt.imshow(final_image,cmap='gray')\n",
    "plt.title(\"Final Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "##### Q. 2. Build a CNN(LeNet5) model from scratch to recognize handwritten digit from the optical handwritten digit dataset(Use Sklearn Dataset and split dataset into training dataset (80%) and testing dataset (20%) ). Use a Stochastic gradient descent algorithm to learn model with parameters for α = 0.01 and random parameters of the CNN model for \n",
    "- (a) Softmax loss function \n",
    "- (b) Focal loss function.\n",
    "    - (i) Plot a comparative loss curve for at least 200 epochs. \n",
    "    - (ii) Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy on test datset and ROC curve for each loss function. \n",
    "    - (iii) Repeat part (i) to (ii) using an Adam gradient descent algorithm \n",
    "    - (iv) Implement above CNN model with Keras/Tensorflow/Pytorch Library and verify the above results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for debugging\n",
    "def check_nan(Layer_name,**variables):\n",
    "    if any(np.isnan(val).any() for val in variables.values()):\n",
    "        print(\"************* nan detected at {}! *************\\n\".format(layer_name))\n",
    "        for key,value in variables.items():\n",
    "            print(\"Variable \",key,\":\")\n",
    "            print(value,\"\\n\")\n",
    "\n",
    "## Required layers\n",
    "\n",
    "# Conv2D\n",
    "class conv2d_layer:\n",
    "    def __init__(self,shape,n,anything_else = None):\n",
    "        self.w = np.random.rand(n,shape[0],shape[1],shape[2])/(np.product(shape)+1)\n",
    "        self.b = np.random.rand(n)/(np.product(shape)+1)\n",
    "        self.n = n\n",
    "        \n",
    "    def forward(self,Image):    \n",
    "        \n",
    "        if(len(Image.shape)==2):\n",
    "            Image=np.reshape(Image,(1,Image.shape[0],Image.shape[1]))\n",
    "            \n",
    "        x,y = Image[0].shape\n",
    "\n",
    "        _ , x_k , y_k = self.w[0].shape\n",
    "\n",
    "        out_x = x-x_k+1\n",
    "        out_y = y-y_k+1\n",
    "        \n",
    "        output = []\n",
    "        \n",
    "        for pos in range(self.n):\n",
    "            out = np.zeros((out_x,out_y))\n",
    "            \n",
    "            for i in range(out_x):\n",
    "                for j in range(out_y):\n",
    "                    out[i,j] = np.sum(Image[:,i:i+x_k,j:j+y_k]*self.w[pos]) + self.b[pos]\n",
    "            output = output + [out]\n",
    "        output = np.array(output)      \n",
    "            \n",
    "#         check_nan(Layer_name = \"conv2d_layer forward step\",\n",
    "#                   output = output,\n",
    "#                   Image = Image,\n",
    "#                   self_Weight = self.w,\n",
    "#                   self_Bias = self.b)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def reverse(self,Image,Errors):\n",
    "        \n",
    "        if(len(Image.shape)==2):\n",
    "            Image=np.reshape(Image,(1,Image.shape[0],Image.shape[1]))\n",
    "            \n",
    "        x,y = Image[0].shape\n",
    "        _ ,x_k,y_k = self.w[0].shape\n",
    "        err_x,err_y = Errors[0].shape\n",
    "        \n",
    "        output = np.zeros_like(Image,Errors.dtype)\n",
    "        for layer in range(self.n):\n",
    "            for i in range(err_x):\n",
    "                for j in range(err_y):\n",
    "                    output[:,i:i+x_k,j:j+y_k] += Errors[layer,i,j]*self.w[layer]\n",
    "                    self.w[layer] = self.w[layer] - Errors[layer,i,j]*Image[:,i:i+x_k,j:j+y_k]\n",
    "                    self.b[layer] = self.b[layer] - Errors[layer,i,j]\n",
    "                \n",
    "#         check_nan(Layer_name = \"conv2d_layer reverse step\",\n",
    "#                   output = output,\n",
    "#                   Image = Image,\n",
    "#                   Errors = Errors,\n",
    "#                   Weights = self.w,\n",
    "#                   Bias = self.b)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def display(self):\n",
    "        print(\"\\n**********Convolution Parameters**********\")\n",
    "        print(\"Weights are:\\n\", self.w)\n",
    "        print(\"Bias is:\\n \", self.b)\n",
    "        print(\"#Kernels is:\\n \", self.n)\n",
    "        \n",
    "# tanh\n",
    "class tanh:\n",
    "    \n",
    "    def forward(self,Input):\n",
    "        exp = np.exp(-2*Input)\n",
    "        output = (1-exp)/(1+exp)\n",
    "        \n",
    "#         check_nan(Layer_name = \"tanh forward step\",\n",
    "#           Input = Input,\n",
    "#           output = output)\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    def reverse(self,Input,Errors):\n",
    "        der = 1-np.square(self.forward(Input))\n",
    "        output = der*Errors\n",
    "        \n",
    "#         check_nan(Layer_name = \"tanh reverse step\",\n",
    "#                   Input = Input,\n",
    "#                   Errors = Errors,\n",
    "#                   output = output,\n",
    "#                   der = der)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# AveragePooling2D\n",
    "class AveragePooling2D:\n",
    "    \n",
    "    def __init__(self,shape,stride,anything_else = None):\n",
    "        self.shape = shape\n",
    "        self.stride = stride\n",
    "        \n",
    "    def forward(self,Image):  \n",
    "        if(len(Image.shape)==2):\n",
    "            Image=np.reshape(Image,(1,Image.shape[0],Image.shape[1]))\n",
    "            \n",
    "        x,y = Image[0].shape\n",
    "        s=self.stride\n",
    "        x_k,y_k = self.shape\n",
    "        \n",
    "        out_x = (x-x_k)//s+1\n",
    "        out_y = (y-y_k)//s+1\n",
    "\n",
    "        output = []\n",
    "        for pos in range(Image.shape[0]):\n",
    "            \n",
    "            out = np.zeros((out_x,out_y))\n",
    "\n",
    "            for i in range(out_x):\n",
    "                for j in range(out_y):\n",
    "                    out[i,j] = np.mean(Image[0][i*s:i*s+x_k,j*s:j*s+y_k])\n",
    "            output = output + [out]\n",
    "            \n",
    "        output = np.array(output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def reverse(self,Image,Errors):\n",
    "        if(len(Image.shape)==2):\n",
    "            Image=np.reshape(Image,(1,Image.shape[0],Image.shape[1]))\n",
    "        \n",
    "        x,y = Image[0].shape\n",
    "        x_k,y_k = self.shape\n",
    "        err_x,err_y = Errors[0].shape\n",
    "            \n",
    "        output = []\n",
    "        for pos in range(Image.shape[0]):\n",
    "\n",
    "            out = np.zeros_like(Image[pos],Errors.dtype)\n",
    "\n",
    "            for i in range(err_x):\n",
    "                for j in range(err_y):\n",
    "                    out[i:i+x_k,j:j+y_k] += Errors[pos,i,j]/(x_k*y_k)\n",
    "            output = output + [out]\n",
    "        output = np.array(output)\n",
    "        return output\n",
    "    \n",
    "# Flatten\n",
    "class flatten():\n",
    "    \n",
    "    def forward(self,Image):\n",
    "        output = np.reshape(Image,np.product(Image.shape))\n",
    "        return output\n",
    "    \n",
    "    def reverse(self,Image,errors):\n",
    "        output = np.reshape(errors,Image.shape)\n",
    "        return output\n",
    "\n",
    "# Dense\n",
    "class fully_connected():\n",
    "    def __init__(self,input_size,n):\n",
    "        \n",
    "        self.w = np.random.rand(n,input_size)/(input_size+1)\n",
    "        self.b = np.random.rand(n)/(input_size+1)\n",
    "        self.n = n\n",
    "    \n",
    "    def forward(self,Input):\n",
    "        output = []\n",
    "        for layer in range(self.n):\n",
    "            out = np.dot(Input,self.w[layer]) + self.b[layer]\n",
    "            output = output + [out]\n",
    "        output = np.array(output)\n",
    "        return output\n",
    "    \n",
    "    def reverse(self,Input,errors):\n",
    "        \n",
    "        output = np.zeros_like(Input)\n",
    "        for layer in range(self.n):\n",
    "            self.w[layer] = self.w[layer] - errors[layer]*Input\n",
    "            self.b[layer] = self.b[layer] - errors[layer]\n",
    "            output = output + errors[layer]*self.w[layer]   \n",
    "        output = np.array(output)\n",
    "        return output\n",
    "    \n",
    "# softmax\n",
    "class softmax():\n",
    "    \n",
    "    def forward(self,Input):\n",
    "\n",
    "        Numerator = np.exp(Input)\n",
    "        output = Numerator/sum(Numerator)\n",
    "        \n",
    "        return (output)\n",
    "    \n",
    "    def reverse(self,Input,errors):\n",
    "            \n",
    "        Soft = self.forward(Input)\n",
    "        \n",
    "        Soft_list = np.array([list(Soft)] * len(Soft))\n",
    "        derivative = Soft_list.T*(np.identity(len(Soft)) - Soft_list)\n",
    "        \n",
    "        output = np.matmul(errors,derivative)\n",
    "        \n",
    "        return output\n",
    "\n",
    "def SoftmaxLoss(truth,predicted):\n",
    "    \n",
    "    loss = -1* np.sum(truth*np.log(predicted))\n",
    "    \n",
    "    Numerator = np.exp(predicted)\n",
    "    softmax = Numerator/sum(Numerator)\n",
    "        \n",
    "    grad = softmax\n",
    "    grad[truth == 1] = softmax[truth == 1] - 1\n",
    "    \n",
    "    return (loss,grad)\n",
    "# Must work for both adam as well as SGD algos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp =  conv2d_layer((2,5,5),2)\n",
    "Img = np.array([\n",
    "    [\n",
    "    [1,2,3,3,2],\n",
    "    [1,3,5,2,3],\n",
    "    [2,5,3,1,2],\n",
    "    [3,1,2,1,2],\n",
    "    [5,2,4,3,1]],\n",
    "    [\n",
    "    [1,2,3,3,2],\n",
    "    [1,3,5,2,3],\n",
    "    [2,5,3,1,2],\n",
    "    [3,1,2,1,2],\n",
    "    [5,2,4,3,1]]\n",
    "])\n",
    "\n",
    "temp.forward(Img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = [] #Input = 1*32*32\n",
    "\n",
    "#Layer 0\n",
    "Model = Model + [conv2d_layer((1,5,5),6)] #Out = 6*28*28\n",
    "\n",
    "#Layer 1\n",
    "Model = Model + [tanh()] #Out = 6*28*28\n",
    "\n",
    "#Layer 2\n",
    "Model = Model + [AveragePooling2D((2,2),2)] # Out = 6*14*14\n",
    "\n",
    "#Layer 3\n",
    "Model = Model + [conv2d_layer((6,5,5),16)] #Out = 16*10*10\n",
    "\n",
    "#Layer 4\n",
    "Model = Model + [tanh()] #Out = 16*10*10\n",
    "\n",
    "#Layer 5\n",
    "Model = Model + [AveragePooling2D((2,2),2)]# Out = 16*5*5\n",
    "\n",
    "#Layer 6\n",
    "Model = Model + [conv2d_layer((16,5,5),120)] #Out = 120*1*1\n",
    "\n",
    "#Layer 7\n",
    "Model = Model + [tanh()] #Out = 120*1*1\n",
    "\n",
    "#Layer 8\n",
    "Model = Model + [flatten()] #Out = 120\n",
    "\n",
    "#Layer 9\n",
    "Model = Model + [fully_connected(120,84)] #Out = 84\n",
    "\n",
    "#Layer 10\n",
    "Model = Model + [tanh()] #Out = 84\n",
    "\n",
    "#Layer 11\n",
    "Model = Model + [fully_connected(84,10)] #Out = 10\n",
    "\n",
    "#Layer 12\n",
    "Model = Model + [softmax()] #Out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read dataset\n",
    "from sklearn.datasets import load_digits\n",
    "data = load_digits()\n",
    "list(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x = data['images']/16\n",
    "y = data['target']\n",
    "col_names = data['target_names']\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "Recorded_loss = []\n",
    "Learning_rate = 0.01\n",
    "\n",
    "x_train = x_train[:50]\n",
    "y_train = y_train[:50]\n",
    "\n",
    "n_layers = len(Model)\n",
    "for ep in tqdm.tqdm(range(epochs),leave=True,desc = \"Epochs\"):\n",
    "    \n",
    "    Data = tqdm.tqdm(zip(x_train,y_train),total = len(y_train),leave=False,desc = \"Images\")\n",
    "    \n",
    "    for Input_img,truth in Data:\n",
    "        \n",
    "        truth_onehot = np.array([0]*10)\n",
    "        truth_onehot[truth] = 1\n",
    "        \n",
    "        outputs = [cv2.resize(Input_img,(32,32))]\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            out = Model[i].forward(outputs[-1])\n",
    "#             print(i,out.shape)\n",
    "#             print(out)\n",
    "            outputs += [out.copy()]\n",
    "            \n",
    "    \n",
    "        Loss, error = SoftmaxLoss(truth_onehot,outputs[-1])\n",
    "#         print(Loss,error)\n",
    "        error = error * Learning_rate\n",
    "        Recorded_loss += [Loss] \n",
    "        \n",
    "        Data.set_description(\"Current loss is: {}\".format(np.round(Loss,5)))\n",
    "        Data.refresh()\n",
    "        \n",
    "#         print(\"\\n\\nTruth:\\n\",truth_onehot,\"\\nPrediction:\\n\",outputs[-1])\n",
    "#         print(\"Epoch: \",ep ,\"\\nLoss:\",Loss)\n",
    "        \n",
    "        error = [error]\n",
    "        for i in range(n_layers-1,-1,-1):\n",
    "#             print(\"Reversing layer {}.\".format(i))\n",
    "            out = Model[i].reverse(outputs[i],error[-1])\n",
    "            error += [out.copy()]\n",
    "            \n",
    "#         error.reverse()\n",
    "#         for i in range(len(error)): \n",
    "#             print(\"\\n*******************Output of layer {} is:*******************\\n\\n\".format(i-1),outputs[i])\n",
    "#             print(\"\\n*******************Gradient entering layer {} output:*******************\\n\\n\".format(i-1),error[i])\n",
    "    \n",
    "    Data.set_description(\"Completed\")\n",
    "    Data.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Recorded_loss)\n",
    "plt.title(\"Error per image ('Stochastic')\")\n",
    "\n",
    "val = 100\n",
    "Avg_loss = []\n",
    "for i in range(len(Recorded_loss)-val):\n",
    "    Avg_loss +=  [np.mean(Recorded_loss[i:i+val])]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss after smoothing\")\n",
    "plt.plot(Avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion Matrix\n",
    "\n",
    "prediction = []\n",
    "test_set = x_test[0:50]\n",
    "\n",
    "for Input_img in tqdm.tqdm(test_set,total = len(test_set)):\n",
    "    outputs = [cv2.resize(Input_img,(32,32))]\n",
    "    for i in range(n_layers):\n",
    "        out = Model[i].forward(outputs[-1])\n",
    "        outputs += [out.copy()]\n",
    "    prediction += [np.argmax(out)]\n",
    "    \n",
    "y_actu = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(prediction, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (32, 32)\n",
    "x_train = np.array([cv2.resize(x_train[i],size) for i in range(x_train.shape[0])])\n",
    "x_train = np.reshape(x_train, (len(x_train), 32, 32, 1))\n",
    "x_test = np.array([cv2.resize(x_test[i],size) for i in range(x_test.shape[0])])\n",
    "x_test = np.reshape(x_test, (len(x_test), 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train).values\n",
    "y_test_val = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=6, kernel_size=(5,5), padding='same', activation='tanh', input_shape=(32, 32, 1)))\n",
    "model.add(AvgPool2D(strides=2))\n",
    "model.add(Conv2D(filters=16, kernel_size=(5,5), padding='valid', activation='tanh'))\n",
    "model.add(AvgPool2D(strides=2))\n",
    "model.add(Conv2D(filters=120, kernel_size=(5,5), padding='valid', activation='tanh'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120, activation='tanh'))\n",
    "model.add(Dense(84, activation='tanh'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=5e-4)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x= x_train,y= y_train, batch_size=1, epochs=epochs, verbose=0,callbacks=[TqdmCallback(verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(x_test)\n",
    "prediction = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion Matrix\n",
    "    \n",
    "y_actu = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(prediction, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q.3. Build CNN(LeNet5) model from scratch to recognize diabetes-fromPima-Indians-diabetes\u0002database (i.e. https://github.com/duonghuuphuc/keras/tree/master/dataset ). Use Adamgradient descent algorithm to learn model with parameters for α = 0.01 and random parameters of theCNN model for Binary cross entropy loss function. \n",
    "- (i) Visualize input dataset and Plot comparative loss curve for at least 200 epochs. \n",
    "- (ii) Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy on test datsetand ROC curve for each loss function. \n",
    "- (iii) Implement above CNN model with Keras/Tensorflow/Pytorch Library and verify the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BinaryCrossEntropy(y_truth,y_pred):\n",
    "    Loss = -1* (y_truth*np.log(y_pred) + (1-y_truth)*np.log(1-y_pred))\n",
    "    grad = -1* ((y_truth/y_pred) - (1-y_truth)/(1-y_pred))\n",
    "    return (Loss,grad)\n",
    "\n",
    "class sigmoid:\n",
    "    \n",
    "    def forward(self,Input):\n",
    "        output = 1/(1+np.exp(-1*Input))\n",
    "        return output\n",
    "    \n",
    "    def reverse(self,Input,Errors):\n",
    "        sig = self.forward(Input)\n",
    "        output = sig*(1-sig)*Errors\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load and display dataset\n",
    "\n",
    "path = \"Data/\"\n",
    "data = pd.read_csv(path+'pima-indians-diabetes.csv',header=None)\n",
    "print(data.info())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "\n",
    "x = np.array(data.drop(8,axis = 1))\n",
    "y = np.array(data[8])\n",
    "\n",
    "x = x/np.max(x,axis = 0)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = [] #Input = 1*32*32\n",
    "\n",
    "#Layer 0\n",
    "Model = Model + [fully_connected(8,30)] #Out = 84\n",
    "\n",
    "#Layer 1\n",
    "Model = Model + [tanh()] #Out = 84\n",
    "\n",
    "#Layer 2\n",
    "Model = Model + [fully_connected(30,10)] #Out = 10\n",
    "\n",
    "#Layer 3\n",
    "Model = Model + [tanh()] #Out = 84\n",
    "\n",
    "#Layer 4\n",
    "Model = Model + [fully_connected(10,1)] #Out = 10\n",
    "\n",
    "#Layer 5\n",
    "Model = Model + [sigmoid()] #Out = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "Recorded_loss = []\n",
    "Learning_rate = 0.01\n",
    "\n",
    "\n",
    "n_layers = len(Model)\n",
    "for ep in tqdm.tqdm(range(epochs),leave=True,desc = \"Epochs\"):\n",
    "    \n",
    "    Data = tqdm.tqdm(zip(x_train,y_train),total = len(y_train),leave=False,desc = \"Images\")\n",
    "    \n",
    "    for Input_img,truth in Data:\n",
    "        \n",
    "        outputs = [Input_img]\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            out = Model[i].forward(outputs[-1])\n",
    "#             print(i,out.shape)\n",
    "#             print(out)\n",
    "            outputs += [out.copy()]\n",
    "            \n",
    "    \n",
    "        Loss, error = BinaryCrossEntropy(truth,outputs[-1][0])\n",
    "#         print(Loss,error)\n",
    "        error = error * Learning_rate\n",
    "        Recorded_loss += [Loss] \n",
    "        \n",
    "        Data.set_description(\"Current loss is: {}\".format(np.round(Loss,5)))\n",
    "        Data.refresh()\n",
    "        \n",
    "#         print(\"\\n\\nTruth:\\n\",truth_onehot,\"\\nPrediction:\\n\",outputs[-1])\n",
    "#         print(\"Epoch: \",ep ,\"\\nLoss:\",Loss)\n",
    "        \n",
    "        error = [error]\n",
    "        for i in range(n_layers-1,-1,-1):\n",
    "#             print(\"Reversing layer {}.\".format(i))\n",
    "            out = Model[i].reverse(outputs[i],error[-1])\n",
    "            error += [out.copy()]\n",
    "            \n",
    "#         error.reverse()\n",
    "#         for i,layer in enumerate(error): \n",
    "#             print(\"\\n*******************Output of layer {} is:*******************\\n\\n\".format(i-1),outputs[i])\n",
    "#             print(\"\\n*******************Error in layer {} output:*******************\\n\\n\".format(i-1),layer)\n",
    "    \n",
    "    Data.set_description(\"Completed\")\n",
    "    Data.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Recorded_loss)\n",
    "plt.title(\"Error per image ('Stochastic')\")\n",
    "\n",
    "val = 1200\n",
    "Avg_loss = []\n",
    "for i in range(len(Recorded_loss)-val):\n",
    "    Avg_loss +=  [np.mean(Recorded_loss[i:i+val])]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss after smoothing\")\n",
    "plt.plot(Avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion Matrix\n",
    "\n",
    "prediction = []\n",
    "test_set = x_test[0:50]\n",
    "\n",
    "for Input_img in tqdm.tqdm(test_set,total = len(test_set)):\n",
    "    outputs = [Input_img]\n",
    "    for i in range(n_layers):\n",
    "        out = Model[i].forward(outputs[-1])\n",
    "        outputs += [out.copy()]\n",
    "    prediction += [np.argmax(out)]\n",
    "    \n",
    "y_actu = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(prediction, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Keras Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(50, activation='tanh', input_shape=(8,)))\n",
    "model_2.add(Dense(40, activation='tanh'))\n",
    "model_2.add(Dense(30, activation='tanh'))\n",
    "model_2.add(Dense(20, activation='tanh'))\n",
    "model_2.add(Dense(10, activation='tanh'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.build()\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(x= x_train,y= y_train, batch_size=1, epochs=epochs, verbose=0,callbacks=[TqdmCallback(verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model_2.predict(x_test)\n",
    "prediction = np.argmax(predicted, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion Matrix\n",
    "    \n",
    "y_actu = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(prediction, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q. 4. Build a CNNmodel from scratch to recognize human emotion using Facial emotionrecognition dataset (FER2013) (https://github.com/gitshanks/fer2013)(split dataset into training dataset (80%) and testing dataset (20%) ). For implementation, use a Adam gradient descent algorithm to learn model with parameters for α = 0.01 and random parameters of the CNN model forthe Softmax loss function \n",
    "- (i)Visualize Facial emotion recognition dataset (FER2013). \n",
    "- (ii) Plot a comparative loss curve for at least 200 epochs. \n",
    "- (iii)Print confusion matrix, calculate classification metrics such as precision, recall, f1-score and accuracy on test dataset and ROC curve \n",
    "- (iv) Implement above CNN model withKeras/Tensorflow/Pytorch Library and verify the above results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading and viewing data\n",
    "\n",
    "path = \"Data/\"\n",
    "data = pd.read_csv(path+'icml_face_data.csv')\n",
    "\n",
    "print(\"List of emotions: \",data['emotion'].unique())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare data\n",
    "def prepare_data(data):\n",
    "    \"\"\" Prepare data for modeling \n",
    "        input: data frame with labels und pixel data\n",
    "        output: image and label array \"\"\"\n",
    "    \n",
    "    image_array = np.zeros(shape=(len(data), 48, 48))\n",
    "    image_label = np.array(list(map(int, data['emotion'])))\n",
    "    \n",
    "    for i, row in enumerate(data.index):\n",
    "        image = np.fromstring(data.loc[row, ' pixels'], dtype=int, sep=' ')\n",
    "        image = np.reshape(image, (48, 48))\n",
    "        image_array[i] = image\n",
    "        \n",
    "    return image_array, image_label\n",
    "\n",
    "#Prepare data\n",
    "x,y = prepare_data(data)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size =0.2)\n",
    "\n",
    "print(np.shape(x_train),np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize Facial emotion recognition dataset\n",
    "\n",
    "plt.figure()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    t= np.random.randint(28709)\n",
    "    plt.title(\"Emotion: {}\".format(y_train[t]))\n",
    "    plt.imshow(x_train[t])\n",
    "\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = [] #Input = 1*32*32\n",
    "\n",
    "#Layer 0\n",
    "Model = Model + [conv2d_layer((1,5,5),6)] #Out = 6*28*28\n",
    "\n",
    "#Layer 1\n",
    "Model = Model + [tanh()] #Out = 6*28*28\n",
    "\n",
    "#Layer 2\n",
    "Model = Model + [AveragePooling2D((2,2),2)] # Out = 6*14*14\n",
    "\n",
    "#Layer 3\n",
    "Model = Model + [conv2d_layer((6,5,5),16)] #Out = 16*10*10\n",
    "\n",
    "#Layer 4\n",
    "Model = Model + [tanh()] #Out = 16*10*10\n",
    "\n",
    "#Layer 5\n",
    "Model = Model + [AveragePooling2D((2,2),2)]# Out = 16*5*5\n",
    "\n",
    "#Layer 6\n",
    "Model = Model + [conv2d_layer((16,5,5),120)] #Out = 120*1*1\n",
    "\n",
    "#Layer 7\n",
    "Model = Model + [tanh()] #Out = 120*1*1\n",
    "\n",
    "#Layer 8\n",
    "Model = Model + [flatten()] #Out = 120\n",
    "\n",
    "#Layer 9\n",
    "Model = Model + [fully_connected(120,84)] #Out = 84\n",
    "\n",
    "#Layer 10\n",
    "Model = Model + [tanh()] #Out = 84\n",
    "\n",
    "#Layer 11\n",
    "Model = Model + [fully_connected(84,7)] #Out = 10\n",
    "\n",
    "#Layer 12\n",
    "Model = Model + [softmax()] #Out = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "Recorded_loss = []\n",
    "Learning_rate = 0.01\n",
    "\n",
    "x_train = x_train[:50]\n",
    "y_train = y_train[:50]\n",
    "\n",
    "n_layers = len(Model)\n",
    "for ep in tqdm.tqdm(range(epochs),leave=True,desc = \"Epochs\"):\n",
    "    \n",
    "    Data = tqdm.tqdm(zip(x_train,y_train),total = len(y_train),leave=False,desc = \"Images\")\n",
    "    \n",
    "    for Input_img,truth in Data:\n",
    "        \n",
    "        truth_onehot = np.array([0]*7)\n",
    "        truth_onehot[truth] = 1\n",
    "        \n",
    "        outputs = [cv2.resize(Input_img,(32,32))]\n",
    "\n",
    "        for i in range(n_layers):\n",
    "            out = Model[i].forward(outputs[-1])\n",
    "#             print(i,out.shape)\n",
    "#             print(out)\n",
    "            outputs += [out.copy()]\n",
    "            \n",
    "    \n",
    "        Loss, error = SoftmaxLoss(truth_onehot,outputs[-1])\n",
    "#         print(Loss,error)\n",
    "        error = error * Learning_rate\n",
    "        Recorded_loss += [Loss] \n",
    "        \n",
    "        Data.set_description(\"Current loss is: {}\".format(np.round(Loss,5)))\n",
    "        Data.refresh()\n",
    "        \n",
    "#         print(\"\\n\\nTruth:\\n\",truth_onehot,\"\\nPrediction:\\n\",outputs[-1])\n",
    "#         print(\"Epoch: \",ep ,\"\\nLoss:\",Loss)\n",
    "        \n",
    "        error = [error]\n",
    "        for i in range(n_layers-1,-1,-1):\n",
    "#             print(\"Reversing layer {}.\".format(i))\n",
    "            out = Model[i].reverse(outputs[i],error[-1])\n",
    "            error += [out.copy()]\n",
    "            \n",
    "        error.reverse()\n",
    "#         for i,layer in enumerate(error): \n",
    "#             print(\"\\n*******************Output of layer {} is:*******************\\n\\n\".format(i-1),outputs[i])\n",
    "#             print(\"\\n*******************Error in layer {} output:*******************\\n\\n\".format(i-1),layer)\n",
    "    \n",
    "    Data.set_description(\"Completed\")\n",
    "    Data.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Recorded_loss)\n",
    "plt.title(\"Error per image ('Stochastic')\")\n",
    "\n",
    "val = 100\n",
    "Avg_loss = []\n",
    "for i in range(len(Recorded_loss)-val):\n",
    "    Avg_loss +=  [np.mean(Recorded_loss[i:i+val])]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Loss after smoothing\")\n",
    "plt.plot(Avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display confusion Matrix\n",
    "\n",
    "prediction = []\n",
    "test_set = x_test[0:50]\n",
    "\n",
    "for Input_img in tqdm.tqdm(test_set,total = len(test_set)):\n",
    "    outputs = [cv2.resize(Input_img,(32,32))]\n",
    "    for i in range(n_layers):\n",
    "        out = Model[i].forward(outputs[-1])\n",
    "        outputs += [out.copy()]\n",
    "    prediction += [np.argmax(out)]\n",
    "    \n",
    "y_actu = pd.Series(y_test, name='Actual')\n",
    "y_pred = pd.Series(prediction, name='Predicted')\n",
    "df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
